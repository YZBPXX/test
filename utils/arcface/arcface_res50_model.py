import glob
import os
import math
import torch
import numpy as np
import torch.nn as nn
import torch.nn.functional as F


class Model(nn.Module):
  def __init__(self):
    super(Model, self).__init__()
    self._vars = nn.ParameterDict()
    self._regularizer_params = []
    for b in glob.glob(
        os.path.join(os.path.dirname(__file__), "variables", "*.npy")):
      v = torch.from_numpy(np.load(b))
      requires_grad = v.dtype.is_floating_point or v.dtype.is_complex
      self._vars[os.path.basename(b)[:-4]] = nn.Parameter(v, requires_grad=requires_grad)
    self.n_Conv_0 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 3, 'bias': True})
    self.n_Conv_0.weight.data = self._vars["t_685"]
    self.n_Conv_0.bias.data = self._vars["t_686"]
    self.n_BatchNormalization_2 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_2.weight.data = self._vars["layer1_0_bn1_weight"]
    self.n_BatchNormalization_2.bias.data = self._vars["layer1_0_bn1_bias"]
    self.n_BatchNormalization_2.running_mean.data = self._vars["layer1_0_bn1_running_mean"]
    self.n_BatchNormalization_2.running_var.data = self._vars["layer1_0_bn1_running_var"]
    self.n_Conv_3 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_3.weight.data = self._vars["t_688"]
    self.n_Conv_3.bias.data = self._vars["t_689"]
    self.n_Conv_5 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 64, 'bias': True})
    self.n_Conv_5.weight.data = self._vars["t_691"]
    self.n_Conv_5.bias.data = self._vars["t_692"]
    self.n_Conv_6 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 64, 'bias': True})
    self.n_Conv_6.weight.data = self._vars["t_694"]
    self.n_Conv_6.bias.data = self._vars["t_695"]
    self.n_BatchNormalization_8 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_8.weight.data = self._vars["layer1_1_bn1_weight"]
    self.n_BatchNormalization_8.bias.data = self._vars["layer1_1_bn1_bias"]
    self.n_BatchNormalization_8.running_mean.data = self._vars["layer1_1_bn1_running_mean"]
    self.n_BatchNormalization_8.running_var.data = self._vars["layer1_1_bn1_running_var"]
    self.n_Conv_9 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_9.weight.data = self._vars["t_697"]
    self.n_Conv_9.bias.data = self._vars["t_698"]
    self.n_Conv_11 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_11.weight.data = self._vars["t_700"]
    self.n_Conv_11.bias.data = self._vars["t_701"]
    self.n_BatchNormalization_13 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_13.weight.data = self._vars["layer1_2_bn1_weight"]
    self.n_BatchNormalization_13.bias.data = self._vars["layer1_2_bn1_bias"]
    self.n_BatchNormalization_13.running_mean.data = self._vars["layer1_2_bn1_running_mean"]
    self.n_BatchNormalization_13.running_var.data = self._vars["layer1_2_bn1_running_var"]
    self.n_Conv_14 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_14.weight.data = self._vars["t_703"]
    self.n_Conv_14.bias.data = self._vars["t_704"]
    self.n_Conv_16 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_16.weight.data = self._vars["t_706"]
    self.n_Conv_16.bias.data = self._vars["t_707"]
    self.n_BatchNormalization_18 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_18.weight.data = self._vars["layer2_0_bn1_weight"]
    self.n_BatchNormalization_18.bias.data = self._vars["layer2_0_bn1_bias"]
    self.n_BatchNormalization_18.running_mean.data = self._vars["layer2_0_bn1_running_mean"]
    self.n_BatchNormalization_18.running_var.data = self._vars["layer2_0_bn1_running_var"]
    self.n_Conv_19 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_19.weight.data = self._vars["t_709"]
    self.n_Conv_19.bias.data = self._vars["t_710"]
    self.n_Conv_21 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 128, 'bias': True})
    self.n_Conv_21.weight.data = self._vars["t_712"]
    self.n_Conv_21.bias.data = self._vars["t_713"]
    self.n_Conv_22 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 64, 'bias': True})
    self.n_Conv_22.weight.data = self._vars["t_715"]
    self.n_Conv_22.bias.data = self._vars["t_716"]
    self.n_BatchNormalization_24 = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_24.weight.data = self._vars["layer2_1_bn1_weight"]
    self.n_BatchNormalization_24.bias.data = self._vars["layer2_1_bn1_bias"]
    self.n_BatchNormalization_24.running_mean.data = self._vars["layer2_1_bn1_running_mean"]
    self.n_BatchNormalization_24.running_var.data = self._vars["layer2_1_bn1_running_var"]
    self.n_Conv_25 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_25.weight.data = self._vars["t_718"]
    self.n_Conv_25.bias.data = self._vars["t_719"]
    self.n_Conv_27 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_27.weight.data = self._vars["t_721"]
    self.n_Conv_27.bias.data = self._vars["t_722"]
    self.n_BatchNormalization_29 = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_29.weight.data = self._vars["layer2_2_bn1_weight"]
    self.n_BatchNormalization_29.bias.data = self._vars["layer2_2_bn1_bias"]
    self.n_BatchNormalization_29.running_mean.data = self._vars["layer2_2_bn1_running_mean"]
    self.n_BatchNormalization_29.running_var.data = self._vars["layer2_2_bn1_running_var"]
    self.n_Conv_30 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_30.weight.data = self._vars["t_724"]
    self.n_Conv_30.bias.data = self._vars["t_725"]
    self.n_Conv_32 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_32.weight.data = self._vars["t_727"]
    self.n_Conv_32.bias.data = self._vars["t_728"]
    self.n_BatchNormalization_34 = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_34.weight.data = self._vars["layer2_3_bn1_weight"]
    self.n_BatchNormalization_34.bias.data = self._vars["layer2_3_bn1_bias"]
    self.n_BatchNormalization_34.running_mean.data = self._vars["layer2_3_bn1_running_mean"]
    self.n_BatchNormalization_34.running_var.data = self._vars["layer2_3_bn1_running_var"]
    self.n_Conv_35 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_35.weight.data = self._vars["t_730"]
    self.n_Conv_35.bias.data = self._vars["t_731"]
    self.n_Conv_37 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_37.weight.data = self._vars["t_733"]
    self.n_Conv_37.bias.data = self._vars["t_734"]
    self.n_BatchNormalization_39 = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_39.weight.data = self._vars["layer3_0_bn1_weight"]
    self.n_BatchNormalization_39.bias.data = self._vars["layer3_0_bn1_bias"]
    self.n_BatchNormalization_39.running_mean.data = self._vars["layer3_0_bn1_running_mean"]
    self.n_BatchNormalization_39.running_var.data = self._vars["layer3_0_bn1_running_var"]
    self.n_Conv_40 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_40.weight.data = self._vars["t_736"]
    self.n_Conv_40.bias.data = self._vars["t_737"]
    self.n_Conv_42 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 256, 'bias': True})
    self.n_Conv_42.weight.data = self._vars["t_739"]
    self.n_Conv_42.bias.data = self._vars["t_740"]
    self.n_Conv_43 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 128, 'bias': True})
    self.n_Conv_43.weight.data = self._vars["t_742"]
    self.n_Conv_43.bias.data = self._vars["t_743"]
    self.n_BatchNormalization_45 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_45.weight.data = self._vars["layer3_1_bn1_weight"]
    self.n_BatchNormalization_45.bias.data = self._vars["layer3_1_bn1_bias"]
    self.n_BatchNormalization_45.running_mean.data = self._vars["layer3_1_bn1_running_mean"]
    self.n_BatchNormalization_45.running_var.data = self._vars["layer3_1_bn1_running_var"]
    self.n_Conv_46 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_46.weight.data = self._vars["t_745"]
    self.n_Conv_46.bias.data = self._vars["t_746"]
    self.n_Conv_48 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_48.weight.data = self._vars["t_748"]
    self.n_Conv_48.bias.data = self._vars["t_749"]
    self.n_BatchNormalization_50 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_50.weight.data = self._vars["layer3_2_bn1_weight"]
    self.n_BatchNormalization_50.bias.data = self._vars["layer3_2_bn1_bias"]
    self.n_BatchNormalization_50.running_mean.data = self._vars["layer3_2_bn1_running_mean"]
    self.n_BatchNormalization_50.running_var.data = self._vars["layer3_2_bn1_running_var"]
    self.n_Conv_51 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_51.weight.data = self._vars["t_751"]
    self.n_Conv_51.bias.data = self._vars["t_752"]
    self.n_Conv_53 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_53.weight.data = self._vars["t_754"]
    self.n_Conv_53.bias.data = self._vars["t_755"]
    self.n_BatchNormalization_55 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_55.weight.data = self._vars["layer3_3_bn1_weight"]
    self.n_BatchNormalization_55.bias.data = self._vars["layer3_3_bn1_bias"]
    self.n_BatchNormalization_55.running_mean.data = self._vars["layer3_3_bn1_running_mean"]
    self.n_BatchNormalization_55.running_var.data = self._vars["layer3_3_bn1_running_var"]
    self.n_Conv_56 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_56.weight.data = self._vars["t_757"]
    self.n_Conv_56.bias.data = self._vars["t_758"]
    self.n_Conv_58 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_58.weight.data = self._vars["t_760"]
    self.n_Conv_58.bias.data = self._vars["t_761"]
    self.n_BatchNormalization_60 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_60.weight.data = self._vars["layer3_4_bn1_weight"]
    self.n_BatchNormalization_60.bias.data = self._vars["layer3_4_bn1_bias"]
    self.n_BatchNormalization_60.running_mean.data = self._vars["layer3_4_bn1_running_mean"]
    self.n_BatchNormalization_60.running_var.data = self._vars["layer3_4_bn1_running_var"]
    self.n_Conv_61 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_61.weight.data = self._vars["t_763"]
    self.n_Conv_61.bias.data = self._vars["t_764"]
    self.n_Conv_63 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_63.weight.data = self._vars["t_766"]
    self.n_Conv_63.bias.data = self._vars["t_767"]
    self.n_BatchNormalization_65 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_65.weight.data = self._vars["layer3_5_bn1_weight"]
    self.n_BatchNormalization_65.bias.data = self._vars["layer3_5_bn1_bias"]
    self.n_BatchNormalization_65.running_mean.data = self._vars["layer3_5_bn1_running_mean"]
    self.n_BatchNormalization_65.running_var.data = self._vars["layer3_5_bn1_running_var"]
    self.n_Conv_66 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_66.weight.data = self._vars["t_769"]
    self.n_Conv_66.bias.data = self._vars["t_770"]
    self.n_Conv_68 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_68.weight.data = self._vars["t_772"]
    self.n_Conv_68.bias.data = self._vars["t_773"]
    self.n_BatchNormalization_70 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_70.weight.data = self._vars["layer3_6_bn1_weight"]
    self.n_BatchNormalization_70.bias.data = self._vars["layer3_6_bn1_bias"]
    self.n_BatchNormalization_70.running_mean.data = self._vars["layer3_6_bn1_running_mean"]
    self.n_BatchNormalization_70.running_var.data = self._vars["layer3_6_bn1_running_var"]
    self.n_Conv_71 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_71.weight.data = self._vars["t_775"]
    self.n_Conv_71.bias.data = self._vars["t_776"]
    self.n_Conv_73 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_73.weight.data = self._vars["t_778"]
    self.n_Conv_73.bias.data = self._vars["t_779"]
    self.n_BatchNormalization_75 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_75.weight.data = self._vars["layer3_7_bn1_weight"]
    self.n_BatchNormalization_75.bias.data = self._vars["layer3_7_bn1_bias"]
    self.n_BatchNormalization_75.running_mean.data = self._vars["layer3_7_bn1_running_mean"]
    self.n_BatchNormalization_75.running_var.data = self._vars["layer3_7_bn1_running_var"]
    self.n_Conv_76 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_76.weight.data = self._vars["t_781"]
    self.n_Conv_76.bias.data = self._vars["t_782"]
    self.n_Conv_78 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_78.weight.data = self._vars["t_784"]
    self.n_Conv_78.bias.data = self._vars["t_785"]
    self.n_BatchNormalization_80 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_80.weight.data = self._vars["layer3_8_bn1_weight"]
    self.n_BatchNormalization_80.bias.data = self._vars["layer3_8_bn1_bias"]
    self.n_BatchNormalization_80.running_mean.data = self._vars["layer3_8_bn1_running_mean"]
    self.n_BatchNormalization_80.running_var.data = self._vars["layer3_8_bn1_running_var"]
    self.n_Conv_81 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_81.weight.data = self._vars["t_787"]
    self.n_Conv_81.bias.data = self._vars["t_788"]
    self.n_Conv_83 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_83.weight.data = self._vars["t_790"]
    self.n_Conv_83.bias.data = self._vars["t_791"]
    self.n_BatchNormalization_85 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_85.weight.data = self._vars["layer3_9_bn1_weight"]
    self.n_BatchNormalization_85.bias.data = self._vars["layer3_9_bn1_bias"]
    self.n_BatchNormalization_85.running_mean.data = self._vars["layer3_9_bn1_running_mean"]
    self.n_BatchNormalization_85.running_var.data = self._vars["layer3_9_bn1_running_var"]
    self.n_Conv_86 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_86.weight.data = self._vars["t_793"]
    self.n_Conv_86.bias.data = self._vars["t_794"]
    self.n_Conv_88 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_88.weight.data = self._vars["t_796"]
    self.n_Conv_88.bias.data = self._vars["t_797"]
    self.n_BatchNormalization_90 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_90.weight.data = self._vars["layer3_10_bn1_weight"]
    self.n_BatchNormalization_90.bias.data = self._vars["layer3_10_bn1_bias"]
    self.n_BatchNormalization_90.running_mean.data = self._vars["layer3_10_bn1_running_mean"]
    self.n_BatchNormalization_90.running_var.data = self._vars["layer3_10_bn1_running_var"]
    self.n_Conv_91 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_91.weight.data = self._vars["t_799"]
    self.n_Conv_91.bias.data = self._vars["t_800"]
    self.n_Conv_93 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_93.weight.data = self._vars["t_802"]
    self.n_Conv_93.bias.data = self._vars["t_803"]
    self.n_BatchNormalization_95 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_95.weight.data = self._vars["layer3_11_bn1_weight"]
    self.n_BatchNormalization_95.bias.data = self._vars["layer3_11_bn1_bias"]
    self.n_BatchNormalization_95.running_mean.data = self._vars["layer3_11_bn1_running_mean"]
    self.n_BatchNormalization_95.running_var.data = self._vars["layer3_11_bn1_running_var"]
    self.n_Conv_96 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_96.weight.data = self._vars["t_805"]
    self.n_Conv_96.bias.data = self._vars["t_806"]
    self.n_Conv_98 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_98.weight.data = self._vars["t_808"]
    self.n_Conv_98.bias.data = self._vars["t_809"]
    self.n_BatchNormalization_100 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_100.weight.data = self._vars["layer3_12_bn1_weight"]
    self.n_BatchNormalization_100.bias.data = self._vars["layer3_12_bn1_bias"]
    self.n_BatchNormalization_100.running_mean.data = self._vars["layer3_12_bn1_running_mean"]
    self.n_BatchNormalization_100.running_var.data = self._vars["layer3_12_bn1_running_var"]
    self.n_Conv_101 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_101.weight.data = self._vars["t_811"]
    self.n_Conv_101.bias.data = self._vars["t_812"]
    self.n_Conv_103 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_103.weight.data = self._vars["t_814"]
    self.n_Conv_103.bias.data = self._vars["t_815"]
    self.n_BatchNormalization_105 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_105.weight.data = self._vars["layer3_13_bn1_weight"]
    self.n_BatchNormalization_105.bias.data = self._vars["layer3_13_bn1_bias"]
    self.n_BatchNormalization_105.running_mean.data = self._vars["layer3_13_bn1_running_mean"]
    self.n_BatchNormalization_105.running_var.data = self._vars["layer3_13_bn1_running_var"]
    self.n_Conv_106 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_106.weight.data = self._vars["t_817"]
    self.n_Conv_106.bias.data = self._vars["t_818"]
    self.n_Conv_108 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_108.weight.data = self._vars["t_820"]
    self.n_Conv_108.bias.data = self._vars["t_821"]
    self.n_BatchNormalization_110 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_110.weight.data = self._vars["layer4_0_bn1_weight"]
    self.n_BatchNormalization_110.bias.data = self._vars["layer4_0_bn1_bias"]
    self.n_BatchNormalization_110.running_mean.data = self._vars["layer4_0_bn1_running_mean"]
    self.n_BatchNormalization_110.running_var.data = self._vars["layer4_0_bn1_running_var"]
    self.n_Conv_111 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_111.weight.data = self._vars["t_823"]
    self.n_Conv_111.bias.data = self._vars["t_824"]
    self.n_Conv_113 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 512, 'bias': True})
    self.n_Conv_113.weight.data = self._vars["t_826"]
    self.n_Conv_113.bias.data = self._vars["t_827"]
    self.n_Conv_114 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 256, 'bias': True})
    self.n_Conv_114.weight.data = self._vars["t_829"]
    self.n_Conv_114.bias.data = self._vars["t_830"]
    self.n_BatchNormalization_116 = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_116.weight.data = self._vars["layer4_1_bn1_weight"]
    self.n_BatchNormalization_116.bias.data = self._vars["layer4_1_bn1_bias"]
    self.n_BatchNormalization_116.running_mean.data = self._vars["layer4_1_bn1_running_mean"]
    self.n_BatchNormalization_116.running_var.data = self._vars["layer4_1_bn1_running_var"]
    self.n_Conv_117 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': True})
    self.n_Conv_117.weight.data = self._vars["t_832"]
    self.n_Conv_117.bias.data = self._vars["t_833"]
    self.n_Conv_119 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': True})
    self.n_Conv_119.weight.data = self._vars["t_835"]
    self.n_Conv_119.bias.data = self._vars["t_836"]
    self.n_BatchNormalization_121 = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_121.weight.data = self._vars["layer4_2_bn1_weight"]
    self.n_BatchNormalization_121.bias.data = self._vars["layer4_2_bn1_bias"]
    self.n_BatchNormalization_121.running_mean.data = self._vars["layer4_2_bn1_running_mean"]
    self.n_BatchNormalization_121.running_var.data = self._vars["layer4_2_bn1_running_var"]
    self.n_Conv_122 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': True})
    self.n_Conv_122.weight.data = self._vars["t_838"]
    self.n_Conv_122.bias.data = self._vars["t_839"]
    self.n_Conv_124 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': True})
    self.n_Conv_124.weight.data = self._vars["t_841"]
    self.n_Conv_124.bias.data = self._vars["t_842"]
    self.n_BatchNormalization_126 = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_126.weight.data = self._vars["bn2_weight"]
    self.n_BatchNormalization_126.bias.data = self._vars["bn2_bias"]
    self.n_BatchNormalization_126.running_mean.data = self._vars["bn2_running_mean"]
    self.n_BatchNormalization_126.running_var.data = self._vars["bn2_running_var"]
    self.n_Flatten_127 = nn.Flatten(**{'start_dim': 1})
    self.n_BatchNormalization_129 = nn.BatchNorm1d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_BatchNormalization_129.weight.data = self._vars["features_weight"]
    self.n_BatchNormalization_129.bias.data = self._vars["features_bias"]
    self.n_BatchNormalization_129.running_mean.data = self._vars["features_running_mean"]
    self.n_BatchNormalization_129.running_var.data = self._vars["features_running_var"]

  def forward(self, *inputs):
    input_1, = inputs
    t_684 = self.n_Conv_0(input_1)
    t_479 = F.prelu(t_684, self._vars["t_843"])
    t_480 = self.n_BatchNormalization_2(t_479)
    t_687 = self.n_Conv_3(t_480)
    t_484 = F.prelu(t_687, self._vars["t_844"])
    t_690 = self.n_Conv_5(t_484)
    t_693 = self.n_Conv_6(t_479)
    t_489 = torch.add(t_690, t_693)
    t_490 = self.n_BatchNormalization_8(t_489)
    t_696 = self.n_Conv_9(t_490)
    t_494 = F.prelu(t_696, self._vars["t_845"])
    t_699 = self.n_Conv_11(t_494)
    t_497 = torch.add(t_699, t_489)
    t_498 = self.n_BatchNormalization_13(t_497)
    t_702 = self.n_Conv_14(t_498)
    t_502 = F.prelu(t_702, self._vars["t_846"])
    t_705 = self.n_Conv_16(t_502)
    t_505 = torch.add(t_705, t_497)
    t_506 = self.n_BatchNormalization_18(t_505)
    t_708 = self.n_Conv_19(t_506)
    t_510 = F.prelu(t_708, self._vars["t_847"])
    t_711 = self.n_Conv_21(t_510)
    t_714 = self.n_Conv_22(t_505)
    t_515 = torch.add(t_711, t_714)
    t_516 = self.n_BatchNormalization_24(t_515)
    t_717 = self.n_Conv_25(t_516)
    t_520 = F.prelu(t_717, self._vars["t_848"])
    t_720 = self.n_Conv_27(t_520)
    t_523 = torch.add(t_720, t_515)
    t_524 = self.n_BatchNormalization_29(t_523)
    t_723 = self.n_Conv_30(t_524)
    t_528 = F.prelu(t_723, self._vars["t_849"])
    t_726 = self.n_Conv_32(t_528)
    t_531 = torch.add(t_726, t_523)
    t_532 = self.n_BatchNormalization_34(t_531)
    t_729 = self.n_Conv_35(t_532)
    t_536 = F.prelu(t_729, self._vars["t_850"])
    t_732 = self.n_Conv_37(t_536)
    t_539 = torch.add(t_732, t_531)
    t_540 = self.n_BatchNormalization_39(t_539)
    t_735 = self.n_Conv_40(t_540)
    t_544 = F.prelu(t_735, self._vars["t_851"])
    t_738 = self.n_Conv_42(t_544)
    t_741 = self.n_Conv_43(t_539)
    t_549 = torch.add(t_738, t_741)
    t_550 = self.n_BatchNormalization_45(t_549)
    t_744 = self.n_Conv_46(t_550)
    t_554 = F.prelu(t_744, self._vars["t_852"])
    t_747 = self.n_Conv_48(t_554)
    t_557 = torch.add(t_747, t_549)
    t_558 = self.n_BatchNormalization_50(t_557)
    t_750 = self.n_Conv_51(t_558)
    t_562 = F.prelu(t_750, self._vars["t_853"])
    t_753 = self.n_Conv_53(t_562)
    t_565 = torch.add(t_753, t_557)
    t_566 = self.n_BatchNormalization_55(t_565)
    t_756 = self.n_Conv_56(t_566)
    t_570 = F.prelu(t_756, self._vars["t_854"])
    t_759 = self.n_Conv_58(t_570)
    t_573 = torch.add(t_759, t_565)
    t_574 = self.n_BatchNormalization_60(t_573)
    t_762 = self.n_Conv_61(t_574)
    t_578 = F.prelu(t_762, self._vars["t_855"])
    t_765 = self.n_Conv_63(t_578)
    t_581 = torch.add(t_765, t_573)
    t_582 = self.n_BatchNormalization_65(t_581)
    t_768 = self.n_Conv_66(t_582)
    t_586 = F.prelu(t_768, self._vars["t_856"])
    t_771 = self.n_Conv_68(t_586)
    t_589 = torch.add(t_771, t_581)
    t_590 = self.n_BatchNormalization_70(t_589)
    t_774 = self.n_Conv_71(t_590)
    t_594 = F.prelu(t_774, self._vars["t_857"])
    t_777 = self.n_Conv_73(t_594)
    t_597 = torch.add(t_777, t_589)
    t_598 = self.n_BatchNormalization_75(t_597)
    t_780 = self.n_Conv_76(t_598)
    t_602 = F.prelu(t_780, self._vars["t_858"])
    t_783 = self.n_Conv_78(t_602)
    t_605 = torch.add(t_783, t_597)
    t_606 = self.n_BatchNormalization_80(t_605)
    t_786 = self.n_Conv_81(t_606)
    t_610 = F.prelu(t_786, self._vars["t_859"])
    t_789 = self.n_Conv_83(t_610)
    t_613 = torch.add(t_789, t_605)
    t_614 = self.n_BatchNormalization_85(t_613)
    t_792 = self.n_Conv_86(t_614)
    t_618 = F.prelu(t_792, self._vars["t_860"])
    t_795 = self.n_Conv_88(t_618)
    t_621 = torch.add(t_795, t_613)
    t_622 = self.n_BatchNormalization_90(t_621)
    t_798 = self.n_Conv_91(t_622)
    t_626 = F.prelu(t_798, self._vars["t_861"])
    t_801 = self.n_Conv_93(t_626)
    t_629 = torch.add(t_801, t_621)
    t_630 = self.n_BatchNormalization_95(t_629)
    t_804 = self.n_Conv_96(t_630)
    t_634 = F.prelu(t_804, self._vars["t_862"])
    t_807 = self.n_Conv_98(t_634)
    t_637 = torch.add(t_807, t_629)
    t_638 = self.n_BatchNormalization_100(t_637)
    t_810 = self.n_Conv_101(t_638)
    t_642 = F.prelu(t_810, self._vars["t_863"])
    t_813 = self.n_Conv_103(t_642)
    t_645 = torch.add(t_813, t_637)
    t_646 = self.n_BatchNormalization_105(t_645)
    t_816 = self.n_Conv_106(t_646)
    t_650 = F.prelu(t_816, self._vars["t_864"])
    t_819 = self.n_Conv_108(t_650)
    t_653 = torch.add(t_819, t_645)
    t_654 = self.n_BatchNormalization_110(t_653)
    t_822 = self.n_Conv_111(t_654)
    t_658 = F.prelu(t_822, self._vars["t_865"])
    t_825 = self.n_Conv_113(t_658)
    t_828 = self.n_Conv_114(t_653)
    t_663 = torch.add(t_825, t_828)
    t_664 = self.n_BatchNormalization_116(t_663)
    t_831 = self.n_Conv_117(t_664)
    t_668 = F.prelu(t_831, self._vars["t_866"])
    t_834 = self.n_Conv_119(t_668)
    t_671 = torch.add(t_834, t_663)
    t_672 = self.n_BatchNormalization_121(t_671)
    t_837 = self.n_Conv_122(t_672)
    t_676 = F.prelu(t_837, self._vars["t_867"])
    t_840 = self.n_Conv_124(t_676)
    t_679 = torch.add(t_840, t_671)
    t_680 = self.n_BatchNormalization_126(t_679)
    t_681 = self.n_Flatten_127(t_680)
    t_682 = 1.0 * torch.matmul(t_681, torch.transpose(self._vars["fc_weight"], 0, 1)) + 1.0 * self._vars["fc_bias"]
    t_682 = torch.unsqueeze(t_682, -1)
    t_683 = self.n_BatchNormalization_129(t_682)
    t_683 = torch.squeeze(t_683, -1)
    return t_683

  def compatible_auto_pad(self, input, kernel_spatial_shape, nn_mod, auto_pad=None, **kwargs):
    input_spatial_shape = input.shape[2:]
    d = len(input_spatial_shape)
    strides = nn_mod.stride
    dilations = nn_mod.dilation
    output_spatial_shape = [math.ceil(float(l) / float(r)) for l, r in zip(input.shape[2:], strides)]
    pt_padding = [0] * 2 * d
    pad_shape = [0] * d
    for i in range(d):
      pad_shape[i] = (output_spatial_shape[i] - 1) * strides[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]
      mean = pad_shape[i] // 2
      if auto_pad == b"SAME_UPPER":
        l, r = pad_shape[i] - mean, mean
      else:
        l, r = mean, pad_shape[i] - mean
      pt_padding.insert(0, r)
      pt_padding.insert(0, l)
    return F.pad(input, pt_padding)


class Model2(nn.Module):
  def __init__(self):
    super(Model2, self).__init__()
    self._vars = nn.ParameterDict()
    self._regularizer_params = []

    self.n_Conv_0 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 3, 'bias': True})
    self.n_BatchNormalization_2 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_3 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_5 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 64, 'bias': True})
    self.n_Conv_6 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 64, 'bias': True})
    self.n_BatchNormalization_8 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_9 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_11 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_BatchNormalization_13 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_14 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_16 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 64, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_BatchNormalization_18 = nn.BatchNorm2d(**{'num_features': 64, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_19 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 64, 'bias': True})
    self.n_Conv_21 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 128, 'bias': True})
    self.n_Conv_22 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 64, 'bias': True})
    self.n_BatchNormalization_24 = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_25 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_27 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_BatchNormalization_29 = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_30 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_32 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_BatchNormalization_34 = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_35 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_37 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 128, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_BatchNormalization_39 = nn.BatchNorm2d(**{'num_features': 128, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_40 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 128, 'bias': True})
    self.n_Conv_42 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 256, 'bias': True})
    self.n_Conv_43 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 128, 'bias': True})
    self.n_BatchNormalization_45 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_46 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_48 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_50 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_51 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_53 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_55 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_56 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_58 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_60 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_61 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_63 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_65 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_66 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_68 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_70 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_71 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_73 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_75 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_76 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_78 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_80 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_81 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_83 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_85 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_86 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_88 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_90 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_91 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_93 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_95 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_96 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_98 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_100 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_101 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_103 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_105 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_106 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_108 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 256, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_110 = nn.BatchNorm2d(**{'num_features': 256, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_111 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 256, 'bias': True})
    self.n_Conv_113 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [2, 2], 'in_channels': 512, 'bias': True})
    self.n_Conv_114 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [0, 0], 'kernel_size': (1, 1), 'stride': [2, 2], 'in_channels': 256, 'bias': True})
    self.n_BatchNormalization_116 = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_117 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': True})
    self.n_Conv_119 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': True})
    self.n_BatchNormalization_121 = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Conv_122 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': True})
    self.n_Conv_124 = nn.Conv2d(**{'groups': 1, 'dilation': [1, 1], 'out_channels': 512, 'padding': [1, 1], 'kernel_size': (3, 3), 'stride': [1, 1], 'in_channels': 512, 'bias': True})
    self.n_BatchNormalization_126 = nn.BatchNorm2d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})
    self.n_Flatten_127 = nn.Flatten(**{'start_dim': 1})
    self.n_BatchNormalization_129 = nn.BatchNorm1d(**{'num_features': 512, 'eps': 9.999999747378752e-06, 'momentum': 0.8999999761581421})

  def forward(self, *inputs):
    input_1, = inputs
    t_684 = self.n_Conv_0(input_1)
    t_479 = F.prelu(t_684, self._vars["t_843"])
    t_480 = self.n_BatchNormalization_2(t_479)
    t_687 = self.n_Conv_3(t_480)
    t_484 = F.prelu(t_687, self._vars["t_844"])
    t_690 = self.n_Conv_5(t_484)
    t_693 = self.n_Conv_6(t_479)
    t_489 = torch.add(t_690, t_693)
    t_490 = self.n_BatchNormalization_8(t_489)
    t_696 = self.n_Conv_9(t_490)
    t_494 = F.prelu(t_696, self._vars["t_845"])
    t_699 = self.n_Conv_11(t_494)
    t_497 = torch.add(t_699, t_489)
    t_498 = self.n_BatchNormalization_13(t_497)
    t_702 = self.n_Conv_14(t_498)
    t_502 = F.prelu(t_702, self._vars["t_846"])
    t_705 = self.n_Conv_16(t_502)
    t_505 = torch.add(t_705, t_497)
    t_506 = self.n_BatchNormalization_18(t_505)
    t_708 = self.n_Conv_19(t_506)
    t_510 = F.prelu(t_708, self._vars["t_847"])
    t_711 = self.n_Conv_21(t_510)
    t_714 = self.n_Conv_22(t_505)
    t_515 = torch.add(t_711, t_714)
    t_516 = self.n_BatchNormalization_24(t_515)
    t_717 = self.n_Conv_25(t_516)
    t_520 = F.prelu(t_717, self._vars["t_848"])
    t_720 = self.n_Conv_27(t_520)
    t_523 = torch.add(t_720, t_515)
    t_524 = self.n_BatchNormalization_29(t_523)
    t_723 = self.n_Conv_30(t_524)
    t_528 = F.prelu(t_723, self._vars["t_849"])
    t_726 = self.n_Conv_32(t_528)
    t_531 = torch.add(t_726, t_523)
    t_532 = self.n_BatchNormalization_34(t_531)
    t_729 = self.n_Conv_35(t_532)
    t_536 = F.prelu(t_729, self._vars["t_850"])
    t_732 = self.n_Conv_37(t_536)
    t_539 = torch.add(t_732, t_531)
    t_540 = self.n_BatchNormalization_39(t_539)
    t_735 = self.n_Conv_40(t_540)
    t_544 = F.prelu(t_735, self._vars["t_851"])
    t_738 = self.n_Conv_42(t_544)
    t_741 = self.n_Conv_43(t_539)
    t_549 = torch.add(t_738, t_741)
    t_550 = self.n_BatchNormalization_45(t_549)
    t_744 = self.n_Conv_46(t_550)
    t_554 = F.prelu(t_744, self._vars["t_852"])
    t_747 = self.n_Conv_48(t_554)
    t_557 = torch.add(t_747, t_549)
    t_558 = self.n_BatchNormalization_50(t_557)
    t_750 = self.n_Conv_51(t_558)
    t_562 = F.prelu(t_750, self._vars["t_853"])
    t_753 = self.n_Conv_53(t_562)
    t_565 = torch.add(t_753, t_557)
    t_566 = self.n_BatchNormalization_55(t_565)
    t_756 = self.n_Conv_56(t_566)
    t_570 = F.prelu(t_756, self._vars["t_854"])
    t_759 = self.n_Conv_58(t_570)
    t_573 = torch.add(t_759, t_565)
    t_574 = self.n_BatchNormalization_60(t_573)
    t_762 = self.n_Conv_61(t_574)
    t_578 = F.prelu(t_762, self._vars["t_855"])
    t_765 = self.n_Conv_63(t_578)
    t_581 = torch.add(t_765, t_573)
    t_582 = self.n_BatchNormalization_65(t_581)
    t_768 = self.n_Conv_66(t_582)
    t_586 = F.prelu(t_768, self._vars["t_856"])
    t_771 = self.n_Conv_68(t_586)
    t_589 = torch.add(t_771, t_581)
    t_590 = self.n_BatchNormalization_70(t_589)
    t_774 = self.n_Conv_71(t_590)
    t_594 = F.prelu(t_774, self._vars["t_857"])
    t_777 = self.n_Conv_73(t_594)
    t_597 = torch.add(t_777, t_589)
    t_598 = self.n_BatchNormalization_75(t_597)
    t_780 = self.n_Conv_76(t_598)
    t_602 = F.prelu(t_780, self._vars["t_858"])
    t_783 = self.n_Conv_78(t_602)
    t_605 = torch.add(t_783, t_597)
    t_606 = self.n_BatchNormalization_80(t_605)
    t_786 = self.n_Conv_81(t_606)
    t_610 = F.prelu(t_786, self._vars["t_859"])
    t_789 = self.n_Conv_83(t_610)
    t_613 = torch.add(t_789, t_605)
    t_614 = self.n_BatchNormalization_85(t_613)
    t_792 = self.n_Conv_86(t_614)
    t_618 = F.prelu(t_792, self._vars["t_860"])
    t_795 = self.n_Conv_88(t_618)
    t_621 = torch.add(t_795, t_613)
    t_622 = self.n_BatchNormalization_90(t_621)
    t_798 = self.n_Conv_91(t_622)
    t_626 = F.prelu(t_798, self._vars["t_861"])
    t_801 = self.n_Conv_93(t_626)
    t_629 = torch.add(t_801, t_621)
    t_630 = self.n_BatchNormalization_95(t_629)
    t_804 = self.n_Conv_96(t_630)
    t_634 = F.prelu(t_804, self._vars["t_862"])
    t_807 = self.n_Conv_98(t_634)
    t_637 = torch.add(t_807, t_629)
    t_638 = self.n_BatchNormalization_100(t_637)
    t_810 = self.n_Conv_101(t_638)
    t_642 = F.prelu(t_810, self._vars["t_863"])
    t_813 = self.n_Conv_103(t_642)
    t_645 = torch.add(t_813, t_637)
    t_646 = self.n_BatchNormalization_105(t_645)
    t_816 = self.n_Conv_106(t_646)
    t_650 = F.prelu(t_816, self._vars["t_864"])
    t_819 = self.n_Conv_108(t_650)
    t_653 = torch.add(t_819, t_645)
    t_654 = self.n_BatchNormalization_110(t_653)
    t_822 = self.n_Conv_111(t_654)
    t_658 = F.prelu(t_822, self._vars["t_865"])
    t_825 = self.n_Conv_113(t_658)
    t_828 = self.n_Conv_114(t_653)
    t_663 = torch.add(t_825, t_828)
    t_664 = self.n_BatchNormalization_116(t_663)
    t_831 = self.n_Conv_117(t_664)
    t_668 = F.prelu(t_831, self._vars["t_866"])
    t_834 = self.n_Conv_119(t_668)
    t_671 = torch.add(t_834, t_663)
    t_672 = self.n_BatchNormalization_121(t_671)
    t_837 = self.n_Conv_122(t_672)
    t_676 = F.prelu(t_837, self._vars["t_867"])
    t_840 = self.n_Conv_124(t_676)
    t_679 = torch.add(t_840, t_671)
    t_680 = self.n_BatchNormalization_126(t_679)
    t_681 = self.n_Flatten_127(t_680)
    t_682 = 1.0 * torch.matmul(t_681, torch.transpose(self._vars["fc_weight"], 0, 1)) + 1.0 * self._vars["fc_bias"]
    t_682 = torch.unsqueeze(t_682, -1)
    t_683 = self.n_BatchNormalization_129(t_682)
    t_683 = torch.squeeze(t_683, -1)
    return t_683

  def compatible_auto_pad(self, input, kernel_spatial_shape, nn_mod, auto_pad=None, **kwargs):
    input_spatial_shape = input.shape[2:]
    d = len(input_spatial_shape)
    strides = nn_mod.stride
    dilations = nn_mod.dilation
    output_spatial_shape = [math.ceil(float(l) / float(r)) for l, r in zip(input.shape[2:], strides)]
    pt_padding = [0] * 2 * d
    pad_shape = [0] * d
    for i in range(d):
      pad_shape[i] = (output_spatial_shape[i] - 1) * strides[i] + ((kernel_spatial_shape[i] - 1) * dilations[i] + 1) - input_spatial_shape[i]
      mean = pad_shape[i] // 2
      if auto_pad == b"SAME_UPPER":
        l, r = pad_shape[i] - mean, mean
      else:
        l, r = mean, pad_shape[i] - mean
      pt_padding.insert(0, r)
      pt_padding.insert(0, l)
    return F.pad(input, pt_padding)

